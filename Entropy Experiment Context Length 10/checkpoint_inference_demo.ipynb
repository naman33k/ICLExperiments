{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Checkpoint Inference Demo\n",
        "\n",
        "This notebook demonstrates how to load a trained checkpoint and run inference on examples from the fixed dataset to see how the model performs on individual cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn import functional as F\n",
        "from scipy.stats import entropy\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Import our modules\n",
        "from config import ExperimentConfig\n",
        "from model_training import ModelManager\n",
        "from dataset_setup import DatasetManager\n",
        "from evaluation import Evaluator\n",
        "\n",
        "# Set up device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set up plotting\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint: results/checkpoints/model_depth_12_heads_6_20251023_223242.pt\n",
            "number of parameters: 5.38M\n",
            "Model loaded successfully!\n",
            "Model configuration:\n",
            "  Depth: 12\n",
            "  Heads: 6\n",
            "  Embedding dim: 192\n",
            "  Training iterations: 30000\n",
            "  Final loss: 1.57309\n",
            "  Number of parameters: 5.40M\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "config = ExperimentConfig()\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint_path = \"results/checkpoints/model_depth_12_heads_6_20251023_223242.pt\"\n",
        "print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "\n",
        "model, checkpoint_info = ModelManager.load_checkpoint(checkpoint_path, device)\n",
        "\n",
        "print(f\"Model loaded successfully!\")\n",
        "print(f\"Model configuration:\")\n",
        "print(f\"  Depth: {checkpoint_info['model_config']['depth']}\")\n",
        "print(f\"  Heads: {checkpoint_info['model_config']['heads']}\")\n",
        "print(f\"  Embedding dim: {checkpoint_info['model_config']['n_embd']}\")\n",
        "print(f\"  Training iterations: {checkpoint_info['training_info']['iterations']}\")\n",
        "print(f\"  Final loss: {checkpoint_info['training_info']['final_loss']:.5f}\")\n",
        "print(f\"  Number of parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up dataset manager and get a fixed dataset example\n",
        "dataset_manager = DatasetManager(config)\n",
        "\n",
        "# Create a mixed dataset to get the dictionary\n",
        "mixed_dataset = dataset_manager.create_mixed_dataset()\n",
        "\n",
        "# Create fixed dataset loader (uses dictionary from config)\n",
        "fixed_loader = dataset_manager.create_fixed_dataset_loader()\n",
        "\n",
        "# Get a single example\n",
        "example = next(iter(fixed_loader))\n",
        "a, b = example\n",
        "\n",
        "print(f\"Example shape: input={a.shape}, target={b.shape}\")\n",
        "print(f\"Input sequence: {a[0].tolist()}\")\n",
        "print(f\"Target sequence: {b[0].tolist()}\")\n",
        "\n",
        "# Show the key-value pairs\n",
        "sequence = a[0].tolist()\n",
        "print(f\"\\nKey-Value pairs:\")\n",
        "for i in range(0, len(sequence), 2):\n",
        "    if i+1 < len(sequence):\n",
        "        print(f\"  Position {i//2}: Key={sequence[i]}, Value={sequence[i+1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run inference on the example\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Get logits for the input sequence\n",
        "    logits, _ = model(a.to(device))\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    \n",
        "    # Get predictions for each position\n",
        "    predictions = torch.argmax(probs, dim=-1)\n",
        "    \n",
        "    print(f\"Model predictions:\")\n",
        "    print(f\"Input:  {a[0].tolist()}\")\n",
        "    print(f\"Target: {b[0].tolist()}\")\n",
        "    print(f\"Pred:   {predictions[0].tolist()}\")\n",
        "    \n",
        "    # Calculate accuracy for each position\n",
        "    correct = (predictions[0] == b[0]).float()\n",
        "    accuracy = correct.mean().item()\n",
        "    \n",
        "    print(f\"\\nPosition-wise accuracy: {correct.tolist()}\")\n",
        "    print(f\"Overall accuracy: {accuracy:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze the probability distributions and entropies\n",
        "print(f\"\\nDetailed Analysis:\")\n",
        "print(f\"{'Position':<10} {'True':<8} {'Pred':<8} {'Correct':<8} {'Entropy':<10} {'Top-3 Probs'}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for i in range(min(len(a[0]), len(b[0]), len(predictions[0]))):\n",
        "    true_val = b[0][i].item()\n",
        "    pred_val = predictions[0][i].item()\n",
        "    correct = \"✓\" if true_val == pred_val else \"✗\"\n",
        "    \n",
        "    # Calculate entropy for this position\n",
        "    pos_probs = probs[0, i].cpu().numpy()\n",
        "    pos_entropy = entropy(pos_probs)\n",
        "    \n",
        "    # Get top-3 probabilities\n",
        "    top3_probs, top3_indices = torch.topk(probs[0, i], 3)\n",
        "    top3_str = \", \".join([f\"{idx.item()}:{prob.item():.3f}\" for idx, prob in zip(top3_indices, top3_probs)])\n",
        "    \n",
        "    print(f\"{i:<10} {true_val:<8} {pred_val:<8} {correct:<8} {pos_entropy:<10.3f} {top3_str}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the probability distributions for key positions\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Show probability distributions for the first 6 value positions (odd indices: 1, 3, 5, 7, 9, 11)\n",
        "value_positions = [1, 3, 5, 7, 9, 11]\n",
        "\n",
        "for idx, pos in enumerate(value_positions):\n",
        "    if pos < len(probs[0]):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        # Get probabilities for this position\n",
        "        pos_probs = probs[0, pos].cpu().numpy()\n",
        "        \n",
        "        # Plot top-10 probabilities\n",
        "        top10_probs, top10_indices = torch.topk(probs[0, pos], 10)\n",
        "        \n",
        "        bars = ax.bar(range(len(top10_indices)), top10_probs.cpu().numpy())\n",
        "        \n",
        "        # Highlight the correct answer\n",
        "        true_val = b[0][pos].item()\n",
        "        if true_val in top10_indices:\n",
        "            correct_idx = (top10_indices == true_val).nonzero(as_tuple=True)[0][0]\n",
        "            bars[correct_idx].set_color('red')\n",
        "            bars[correct_idx].set_alpha(0.8)\n",
        "        \n",
        "        ax.set_title(f'Position {pos} (Value)\\nTrue: {true_val}, Pred: {predictions[0][pos].item()}')\n",
        "        ax.set_xlabel('Token Index')\n",
        "        ax.set_ylabel('Probability')\n",
        "        ax.set_xticks(range(len(top10_indices)))\n",
        "        ax.set_xticklabels([str(idx.item()) for idx in top10_indices], rotation=45)\n",
        "        \n",
        "        # Add entropy as text\n",
        "        pos_entropy = entropy(pos_probs)\n",
        "        ax.text(0.02, 0.98, f'Entropy: {pos_entropy:.3f}', \n",
        "                transform=ax.transAxes, verticalalignment='top',\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Probability Distributions for Value Positions', y=1.02, fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the model's ability to learn the fixed pattern\n",
        "print(f\"\\nTesting Fixed Pattern Learning:\")\n",
        "print(f\"Dictionary: {mixed_dataset.dictionary.tolist()}\")\n",
        "\n",
        "# Show how the model should behave for the fixed pattern\n",
        "print(f\"\\nExpected behavior for fixed dataset:\")\n",
        "print(f\"- Early positions should have high confidence (low entropy)\")\n",
        "print(f\"- Later positions should have very high confidence (very low entropy)\")\n",
        "print(f\"- The model should learn the fixed key-value mapping\")\n",
        "\n",
        "# Calculate entropies for value positions only\n",
        "value_entropies = []\n",
        "value_positions = list(range(1, len(probs[0]), 2))  # Odd indices\n",
        "\n",
        "for pos in value_positions:\n",
        "    if pos < len(probs[0]):\n",
        "        pos_probs = probs[0, pos].cpu().numpy()\n",
        "        pos_entropy = entropy(pos_probs)\n",
        "        value_entropies.append(pos_entropy)\n",
        "\n",
        "print(f\"\\nEntropies for value positions: {[f'{e:.3f}' for e in value_entropies]}\")\n",
        "\n",
        "# Plot entropy vs position\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(value_entropies)), value_entropies, 'o-', linewidth=2, markersize=6)\n",
        "plt.xlabel('Value Position Index')\n",
        "plt.ylabel('Entropy')\n",
        "plt.title('Model Entropy vs Position (Fixed Dataset)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(range(0, len(value_entropies), 5))\n",
        "\n",
        "# Add expected pattern (should decrease)\n",
        "expected_entropies = [0.7] + [0.02] + [0.001] + [0.0001] + [0.00001] + [0.000001] + [0.0] * (len(value_entropies) - 6)\n",
        "expected_entropies = expected_entropies[:len(value_entropies)]\n",
        "plt.plot(range(len(expected_entropies)), expected_entropies, 'r--', linewidth=2, label='Expected Pattern')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAnalysis:\")\n",
        "print(f\"- If the model learned the fixed pattern, entropies should decrease rapidly\")\n",
        "print(f\"- High entropies (~3.6-3.8) suggest the model is not learning the pattern\")\n",
        "print(f\"- The model should show high confidence for later positions in fixed dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test with multiple examples to get a better sense of performance\n",
        "print(f\"\\nTesting Multiple Examples:\")\n",
        "\n",
        "# Get several examples\n",
        "examples = []\n",
        "for i, example in enumerate(fixed_loader):\n",
        "    if i >= 5:  # Test 5 examples\n",
        "        break\n",
        "    examples.append(example)\n",
        "\n",
        "accuracies = []\n",
        "entropies_by_position = []\n",
        "\n",
        "for ex_idx, (a, b) in enumerate(examples):\n",
        "    with torch.no_grad():\n",
        "        logits, _ = model(a.to(device))\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        predictions = torch.argmax(probs, dim=-1)\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        correct = (predictions[0] == b[0]).float()\n",
        "        accuracy = correct.mean().item()\n",
        "        accuracies.append(accuracy)\n",
        "        \n",
        "        # Calculate entropies for value positions\n",
        "        value_entropies = []\n",
        "        for pos in range(1, len(probs[0]), 2):\n",
        "            if pos < len(probs[0]):\n",
        "                pos_probs = probs[0, pos].cpu().numpy()\n",
        "                pos_entropy = entropy(pos_probs)\n",
        "                value_entropies.append(pos_entropy)\n",
        "        entropies_by_position.append(value_entropies)\n",
        "        \n",
        "        print(f\"Example {ex_idx+1}: Accuracy = {accuracy:.3f}, Mean Entropy = {np.mean(value_entropies):.3f}\")\n",
        "\n",
        "print(f\"\\nSummary across {len(examples)} examples:\")\n",
        "print(f\"Mean accuracy: {np.mean(accuracies):.3f} ± {np.std(accuracies):.3f}\")\n",
        "print(f\"Mean entropy: {np.mean([np.mean(ents) for ents in entropies_by_position]):.3f}\")\n",
        "\n",
        "# Plot average entropy by position across examples\n",
        "avg_entropies = np.mean(entropies_by_position, axis=0)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(len(avg_entropies)), avg_entropies, 'o-', linewidth=2, markersize=6)\n",
        "plt.xlabel('Value Position Index')\n",
        "plt.ylabel('Average Entropy')\n",
        "plt.title('Average Entropy vs Position (5 Examples)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
